# Linear Regression with PyTorch

This tutorial demonstrates how to implement linear regression using PyTorch with proper neural network components, optimizers, and best practices.

## Topics Covered

- Dataset creation and data loading
- Neural network architecture for regression
- Loss functions (MSE)
- Optimizers (SGD, Adam)
- Training and validation loops
- Model evaluation and visualization
- Device-agnostic implementation

## Prerequisites

- Completion of `01_basics` tutorial
- Understanding of linear regression concepts
- Basic knowledge of machine learning workflows

## Installation

```bash
pip install torch torchvision scikit-learn jupyter numpy matplotlib seaborn pandas
```

## Contents

- `linear_regression.ipynb`: Complete linear regression implementation
- Dataset examples with synthetic and real-world data
- Comparison of different optimizers
- Visualization of training progress

## Key Learning Objectives

- Build regression models using PyTorch's nn.Module
- Implement proper training/validation splits
- Use PyTorch optimizers and loss functions
- Visualize model performance and predictions
- Apply regularization techniques

## Dataset

We'll work with:
1. Synthetic linear data
2. Boston Housing dataset
3. Custom polynomial regression example

## Next Steps

After completing this tutorial:
- 03_classification: Multi-class classification problems
- 04_cnn: Convolutional Neural Networks